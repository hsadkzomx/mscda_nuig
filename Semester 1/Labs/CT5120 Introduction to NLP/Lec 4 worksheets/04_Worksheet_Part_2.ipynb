{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2-PspSFAm2"
      },
      "source": [
        "# Part-of-speech tagging\n",
        "\n",
        "We are going to implement the hidden Markov model using the Brown corpus again. You can get all the tagged words using \n",
        "\n",
        "    brown.tagged_words()\n",
        "\n",
        "Using this can you infer all the probabilities you need for the HMM?\n",
        "\n",
        "_Use a simple smoothing strategy and return `1e-8` if the probability has no examples in the corpus_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbSrfAhbOZDr",
        "outputId": "7d798516-ce83-4513-b996-4e934ca3a085"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")\n",
        "from nltk.corpus import brown\n",
        "from nltk import bigrams, ConditionalFreqDist\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCyZRdmIFcKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dfac88-3754-4622-e535-54c08de5cfb7"
      },
      "source": [
        "emissions = ConditionalFreqDist((w[1], w[0].lower()) for w in brown.tagged_words())\n",
        "transitions = ConditionalFreqDist((b[0][1],b[1][1]) for b in bigrams(brown.tagged_words()))\n",
        "\n",
        "def emit_prob(t, w):\n",
        "  print(\"emit_prob(\",t,\",\",w,\")\")\n",
        "  return 1e-8\n",
        "\n",
        "def trans_prob(t1, t2):\n",
        "  print(\"trans_prob(\",t1,\",\",t2,\")\")\n",
        "  return 1e-8\n",
        "\n",
        "assert emit_prob(\"VB\", \"work\") == 0.005312676223547918\n",
        "assert trans_prob(\"NN\", \"VB\") == 0.003961435036400603"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emit_prob( VB , work )\n",
            "trans_prob( NN , VB )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BSuzRobIt3r"
      },
      "source": [
        "Using this implement the hidden Markov model that takes a sequence of words and a sequence of tags and returns the **log** probability associated with this.\n",
        "\n",
        "_We will make a simplifying hack and treat the start token as equivalent to the symbol `.` i.e., we treat every sentence as following on from another sentence after a full stop_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOSV-q_3I3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c13d3ce-ff11-4ae6-89eb-43147ac42267"
      },
      "source": [
        "def hmm(words,tags):\n",
        "  p = 0.0\n",
        "  for i in range(len(words)):\n",
        "    if i == 0:\n",
        "      p += 0.0\n",
        "    else:\n",
        "      p += 0.0\n",
        "    p += 0.0\n",
        "  return p\n",
        "    \n",
        "assert hmm([\"this\",\"works\"],[\"DT\",\"VBZ\"]) == -13.400840641537089"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trans_prob( . , DT )\n",
            "emit_prob( DT , this )\n",
            "trans_prob( DT , VBZ )\n",
            "emit_prob( VBZ , works )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd1lbFJbKl3p"
      },
      "source": [
        "Let's extend this further to a function that predicts for the next word's part-of-speech tag based on a partial tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vReLvkLK0Nc"
      },
      "source": [
        "all_tags = transitions.keys()\n",
        "\n",
        "def hmm_predict(words, tags, word):\n",
        "  return \"\"\n",
        "  \n",
        "assert hmm_predict([\"this\", \"works\"],[\"DT\",\"VBZ\"],\"well\") == \"RB\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}