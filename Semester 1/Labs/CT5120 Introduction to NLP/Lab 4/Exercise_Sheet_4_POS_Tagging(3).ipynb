{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT8Fekl4ewqq"
   },
   "source": [
    "# Learning Objectives\n",
    "\n",
    "In this lab we are going to:\n",
    "\n",
    "*   Explore POS Tagging using NLTK\n",
    "*   Learn about Hidden Markov Models (HMM)\n",
    "*   Perform POS tagging with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cQM_Wv2AHOJ",
    "outputId": "2310c5c6-2ffe-4e3f-a7dd-5885a58bd0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installing necessary packages from NLTK\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLh8csmUf0-l"
   },
   "source": [
    "# POS Tagging \n",
    "POS tagging is the process of assigning a part-of-speech label to\n",
    "each word in an input text, where the tagging model takes a sequence of words and a tagset as input and gives the output as a sequence of tags one per token. There are various parts of speech tagsets. The most common tagsets are:\n",
    "\n",
    "1- <a href= \"http://ucrel.lancs.ac.uk/claws5tags.html\">Claws5</a>: 62 different tags <br>\n",
    "2- <a href=\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\">Penn Treebank</a>: 45 different tags <br>\n",
    "3- <a href = \"https://en.wikipedia.org/wiki/Brown_Corpus\">The Brown Corpus tagset</a>: (87 tags)<br>\n",
    "4- <a href = \"https://universaldependencies.org/u/pos/\">UD tagset</a>\n",
    "\n",
    "## Approaches\n",
    "\n",
    "POS tagging can be done using different approaches such as:\n",
    " \n",
    "\n",
    "*   Pointwise prediction: a classifier that predicts each word individually such as perceptron.\n",
    "\n",
    "*   Generative sequence models: a probabilistic model that assigns probabilities to sequences of words such as Hidden Markov Model.\n",
    "\n",
    "\n",
    "*   Discriminative sequence models: predict whole sequence with a classifier such as conditional random fields (CRF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyOu22_if9Pp"
   },
   "source": [
    "\n",
    "# NLTK POS Tagging\n",
    "\n",
    "The NLTK tagger can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTylIk5df8NL",
    "outputId": "dc5d8c03-a146-48dc-9c20-8f1688fd035e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# tokenize the sentence before POS tagging\n",
    "text = word_tokenize(\"And is it very interesting for everyone?\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36eoGYFcg4bm"
   },
   "source": [
    "The brown corpus has been manually tagged with part-of-speech tags which is useful for testing taggers and for training statistical taggers. In order to read a tagged corpus we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K254qLzRg677",
    "outputId": "9be8f37b-fa6d-40e1-d32d-1e2eee07f799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "# Accessing manually tagged brown corpus\n",
    "print (brown.tagged_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsOFmUxf_--e"
   },
   "source": [
    "## Exercise 1:\n",
    "Get the count of each POS tag assigned to the word **(ignore case)** \"_dog_\" in the **news** category of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSP62tgn_nVy"
   },
   "outputs": [],
   "source": [
    "# Slicing brown corpus with news category\n",
    "tagged_words = brown.tagged_words(categories='news')\n",
    "\n",
    "# your code goes here;\n",
    "\n",
    "\"\"\"output should be: {'NN': 7}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh3S-fbyAzcl"
   },
   "source": [
    "## Exercise 2:\n",
    "Find the frequency distribution of each tag in the brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdKTPHucV-7f"
   },
   "outputs": [],
   "source": [
    "# your code goes here;\n",
    "\n",
    "# output should be \n",
    "\"\"\"[('NN', 152470),('IN', 120557),('AT', 97959),....]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSEIc7EAjYEq"
   },
   "source": [
    "## Exercise 3:\n",
    "\n",
    "What are the most common verbs in **fiction** category in the brown corpus? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0y6erNBBB-h"
   },
   "outputs": [],
   "source": [
    "# your code goes here;\n",
    "\n",
    "verb_tags = ['VB', 'VBN', 'VBD', 'VBG', 'VBZ']\n",
    "tagged_words = brown.tagged_words(categories=['fiction'])\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "# Answer should be\n",
    "\"\"\"[(('said', 'VBD'), 177),\n",
    " (('came', 'VBD'), 91),\n",
    " (('went', 'VBD'), 79),\n",
    " (('get', 'VB'), 78),\n",
    " (('know', 'VB'), 74)]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzr1U3OLhlzW"
   },
   "source": [
    "# Hidden Markov Model\n",
    "\n",
    "The sequence of tags can be viewed as a Markov chain so let us explore the construction and solution of a Hidden Markov Model. \n",
    "\n",
    "An HMM has two components:\n",
    "\n",
    "*   **Transition Probabilities** which represents the probability of a tag occurring given the previous tag i.e. $P(t_i|t_{i-1})$.\n",
    "  * For Example, modal verbs (`MD`) like *will* are very likely to be followed by a verb in the base form, a `VB`, like *race*, therefore it is more likely that modal verbs will occur with main verb.\n",
    "  * We compute the maximum likelihood estimate of this transition probability by counting, out of the times we see the first tag in a labeled corpus, how often the first tag is followed by the second:\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  P(t_{i} | t_{i-1}) = \\frac{C(t_{i-1}, t_{i})}{C(t_{i-1})} \\\\\n",
    "  P(MD | VB) = \\frac{C(MD, VB)}{C(MD)}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "\n",
    "*   **Emission Probabilities** represents the probability, given a tag that it will be associated with a given word i.e. $P(w_i|t_i)$.\n",
    "  * For Example, probability of a given tag `MD` associated with the word *will* is:\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  P(w_i|t_i) = \\frac{C(t_i, w_i)}{C(t_i)} \\\\\n",
    "  P(will|MD) = \\frac{C(MD, \\text{will})}{C(MD)}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hLzHeEJBb8F"
   },
   "source": [
    "## Exercise 4: \n",
    "\n",
    "Consider that we have an HMM with hidden states Noun, Verb, Adj and the following transition probability where $p(Y_{i+1}|Y_i)$ is the probability of state $Y_{i+1}$ occuring after $Y_i$ and the table of probabilities is as follows:\n",
    "\n",
    "| $p(Y_{i+1}|Y_i)$ | $Y_{i+1}$=Start | $Y_{i+1}$=Noun | $Y_{i+1}$=Verb | $Y_{i+1}$=Adj |\n",
    "|:-----------------|:-----------------|:--------------:|:--------------:|:-------------:|\n",
    "| $Y_i$=Start      | 0.0      |  0.5           |  0.4           | 0.1           |\n",
    "| $Y_i$=Noun       | 0.0       |  0.3           |  0.5           | 0.2           |\n",
    "| $Y_i$=Verb       | 0.0       |  0.7           |  0.2           | 0.1           |\n",
    "| $Y_i$=Adj        | 0.0        |  0.8           |  0.1           | 0.1           |\n",
    "\n",
    "Furthermore, consider that the model has a vocabulary as follows, with the probability of $p(X_i|Y_i)$ as follows \n",
    "\n",
    "| $p(X_i|Y_i)$ | cats | dogs | drink | water | milk | fresh |\n",
    "|:-------------|:----:|:----:|:-----:|:-----:|:----:|:-----:|\n",
    "| $Y_i$=Noun   | 0.2  | 0.2  |  0.2  | 0.2   | 0.1  | 0.0   |\n",
    "| $Y_i$=Verb   | 0.1  | 0.1  | 0.4   | 0.2   | 0.1  | 0.1   |\n",
    "| $Y_i$=Adj    | 0.0  | 0.0  | 0.2   | 0.0   | 0.2  | 0.8   |\n",
    "\n",
    "\n",
    "Implement the above table and write a function that takes a sequence of words and a sequence of part-of-speech tags and returns the probability using the above model. Calculate the probability of the sentence \"*cats drink fresh milk*\" given the tags \"*noun verb adj verb*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4RZV0xS7BiVB"
   },
   "outputs": [],
   "source": [
    "all_tags = [\"start\",\"noun\",\"verb\",\"adj\"]\n",
    "all_words = [\"cats\",\"dogs\",\"drink\",\"water\",\"milk\",\"fresh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM5PV12GULWT"
   },
   "outputs": [],
   "source": [
    "transitions = {\n",
    "  'start': {'noun': 0.5, 'verb': 0.4, 'adj': 0.1, 'start': 0.0},\n",
    "  'noun': {'noun': 0.3, 'verb': 0.5, 'adj': 0.2, 'start': 0.0},\n",
    "  'verb': {'noun': 0.7, 'verb': 0.2, 'adj': 0.1, 'start': 0.0},\n",
    "  'adj': {'noun': 0.8, 'verb': 0.1, 'adj': 0.1, 'start': 0.0},\n",
    "}\n",
    "\n",
    "\n",
    "emissions = {\n",
    "    # your code goes here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_moLAxIRBp7v"
   },
   "outputs": [],
   "source": [
    "def hmm(words, tags):\n",
    "    prob = 1.0\n",
    "    \n",
    "    # your code goes here\n",
    "\n",
    "    return prob\n",
    "\n",
    "print(hmm([\"cats\",\"drink\",\"fresh\",\"milk\"], [\"noun\",\"verb\",\"adj\",\"verb\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWV7FhgxMDI1"
   },
   "source": [
    "## Hint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLF8mJucLCVo"
   },
   "source": [
    "P(Start|noun) x P(cats|noun) x p(drink|verb) x p(verb|noun) x ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIVlRBrNEwbp"
   },
   "source": [
    "## Exercise 5 \n",
    "Write a function that learns the emission and transition probabilities for the Hidden Markov Model using the tagged corpus given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g9A6RFCpEu-y"
   },
   "outputs": [],
   "source": [
    "all_tags = [\"start\",\"noun\",\"verb\",\"adj\"]\n",
    "all_words = [\"cats\",\"dogs\",\"drink\",\"water\",\"milk\",\"fresh\"]\n",
    "\n",
    "sentences = [\n",
    "    [\"cats\",\"drink\",\"milk\"],\n",
    "    [\"dogs\",\"drink\",\"water\"],\n",
    "    [\"fresh\",\"milk\"],\n",
    "    [\"dogs\",\"drink\",\"fresh\",\"milk\"],\n",
    "    [\"cats\",\"milk\"]\n",
    "]\n",
    "\n",
    "tagged = [\n",
    "    [\"noun\",\"verb\",\"noun\"],\n",
    "    [\"noun\",\"verb\",\"noun\"],\n",
    "    [\"adj\",\"noun\"],\n",
    "    [\"noun\",\"verb\",\"adj\",\"noun\"],\n",
    "    [\"noun\",\"noun\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxxjU0_XFBSc"
   },
   "outputs": [],
   "source": [
    "def hmm_learn(sentences, tagged):\n",
    "    transitions = {t:{t2:0.0 for t2 in all_tags} for t in all_tags}\n",
    "    emissions    = {t:{w:0.0 for w in all_words} for t in all_tags}\n",
    "    # your code goes here\n",
    "    return transitions, emissions\n",
    "\n",
    "print(hmm_learn(sentences, tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kFFgYJyUjJk"
   },
   "source": [
    "## Hint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH4hx5TLVaD5"
   },
   "source": [
    "* Iterate through sentence and tag pair\n",
    "* Iterated through word and tag pair\n",
    "* Update the transitions and emission counts\n",
    "* Calculate the transitions_counts total and emissions_counts total by adding counts\n",
    "* normalize the tag counts\n",
    "* normalize the word counts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
