{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT8Fekl4ewqq"
   },
   "source": [
    "# Learning Objectives\n",
    "\n",
    "In this lab we are going to:\n",
    "\n",
    "*   Explore POS Tagging using NLTK\n",
    "*   Learn about Hidden Markov Models (HMM)\n",
    "*   Perform POS tagging with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cQM_Wv2AHOJ",
    "outputId": "2310c5c6-2ffe-4e3f-a7dd-5885a58bd0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/zhejing/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/zhejing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/zhejing/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installing necessary packages from NLTK\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLh8csmUf0-l"
   },
   "source": [
    "# POS Tagging \n",
    "POS tagging is the process of assigning a part-of-speech label to\n",
    "each word in an input text, where the tagging model takes a sequence of words and a tagset as input and gives the output as a sequence of tags one per token. There are various parts of speech tagsets. The most common tagsets are:\n",
    "\n",
    "1- <a href= \"http://ucrel.lancs.ac.uk/claws5tags.html\">Claws5</a>: 62 different tags <br>\n",
    "2- <a href=\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\">Penn Treebank</a>: 45 different tags <br>\n",
    "3- <a href = \"https://en.wikipedia.org/wiki/Brown_Corpus\">The Brown Corpus tagset</a>: (87 tags)<br>\n",
    "4- <a href = \"https://universaldependencies.org/u/pos/\">UD tagset</a>\n",
    "\n",
    "## Approaches\n",
    "\n",
    "POS tagging can be done using different approaches such as:\n",
    " \n",
    "\n",
    "*   Pointwise prediction: a classifier that predicts each word individually such as perceptron.\n",
    "\n",
    "*   Generative sequence models: a probabilistic model that assigns probabilities to sequences of words such as Hidden Markov Model.\n",
    "\n",
    "\n",
    "*   Discriminative sequence models: predict whole sequence with a classifier such as conditional random fields (CRF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyOu22_if9Pp"
   },
   "source": [
    "\n",
    "# NLTK POS Tagging\n",
    "\n",
    "The NLTK tagger can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTylIk5df8NL",
    "outputId": "dc5d8c03-a146-48dc-9c20-8f1688fd035e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('interesting', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('everyone', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# tokenize the sentence before POS tagging\n",
    "text = word_tokenize(\"And is it very interesting for everyone?\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36eoGYFcg4bm"
   },
   "source": [
    "The brown corpus has been manually tagged with part-of-speech tags which is useful for testing taggers and for training statistical taggers. In order to read a tagged corpus we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K254qLzRg677",
    "outputId": "9be8f37b-fa6d-40e1-d32d-1e2eee07f799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "# Accessing manually tagged brown corpus\n",
    "print (brown.tagged_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsOFmUxf_--e"
   },
   "source": [
    "## Exercise 1:\n",
    "Get the count of each POS tag assigned to the word **(ignore case)** \"_dog_\" in the **news** category of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JSP62tgn_nVy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog NN\n",
      "dog NN\n",
      "dog NN\n",
      "dog NN\n",
      "dog NN\n",
      "dog NN\n",
      "dog NN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NN': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing brown corpus with news category\n",
    "tagged_words = brown.tagged_words(categories='news')\n",
    "\n",
    "# your code goes here;\n",
    "tagged_words_count = {}\n",
    "for tag in tagged_words:\n",
    "#     print(tag[0].lower())\n",
    "    if tag[0].lower() in ['dog']:\n",
    "        print(tag[0].lower(), tag[1])\n",
    "        if tag[1] not in tagged_words_count:\n",
    "            tagged_words_count[tag[1]] = 1\n",
    "        else:\n",
    "            tagged_words_count[tag[1]] += 1\n",
    "\n",
    "tagged_words_count\n",
    "# output should be: NN: 37, NN-TL: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh3S-fbyAzcl"
   },
   "source": [
    "## Exercise 2:\n",
    "Find the frequency distribution of each tag in the brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "xdKTPHucV-7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here;\n",
    "tagged_words = brown.tagged_words()\n",
    "tagged_freq = {}\n",
    "for tag in tagged_words:\n",
    "    if tag[1] not in tagged_freq:\n",
    "        tagged_freq[tag[1]] = 1\n",
    "    else:\n",
    "        tagged_freq[tag[1]] += 1\n",
    "        \n",
    "# tagged_freq.items()\n",
    "# [(k,v) for k,v in dict.items()]\n",
    "[(k,v) for k,v in sorted(tagged_freq.items(), key=lambda item: item[1], reverse=True)][:5]\n",
    "# output should be \n",
    "# [('NN', 152470),('IN', 120557),('AT', 97959),....]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSEIc7EAjYEq"
   },
   "source": [
    "## Exercise 3:\n",
    "\n",
    "What are the most common verbs in **fiction** category in the brown corpus? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "n0y6erNBBB-h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('said', 'VBD'), 177),\n",
       " (('came', 'VBD'), 91),\n",
       " (('went', 'VBD'), 79),\n",
       " (('get', 'VB'), 78),\n",
       " (('know', 'VB'), 74)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here;\n",
    "\n",
    "verb_tags = ['VB', 'VBN', 'VBD', 'VBG', 'VBZ']\n",
    "tagged_words = brown.tagged_words(categories=['fiction'])\n",
    "\n",
    "# your code goes here\n",
    "verb_count = {}\n",
    "for tag in tagged_words:\n",
    "    if tag[1] in verb_tags:\n",
    "        if (tag[0], tag[1]) in verb_count:\n",
    "            verb_count[(tag[0], tag[1])] += 1\n",
    "        else:\n",
    "            verb_count[(tag[0], tag[1])] = 1\n",
    "\n",
    "[(k,v) for k,v in sorted(verb_count.items(), key=lambda item: item[1], reverse=True)][:5]\n",
    "\n",
    "# Answer should be\n",
    "# \"\"\"[(('said', 'VBD'), 177),\n",
    "#  (('came', 'VBD'), 91),\n",
    "#  (('went', 'VBD'), 79),\n",
    "#  (('get', 'VB'), 78),\n",
    "#  (('know', 'VB'), 74)]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzr1U3OLhlzW"
   },
   "source": [
    "# Hidden Markov Model\n",
    "\n",
    "The sequence of tags can be viewed as a Markov chain so let us explore the construction and solution of a Hidden Markov Model. \n",
    "\n",
    "An HMM has two components:\n",
    "\n",
    "*   **Transition Probabilities** which represents the probability of a tag occurring given the previous tag i.e. $P(t_i|t_{i-1})$.\n",
    "  * For Example, modal verbs (`MD`) like *will* are very likely to be followed by a verb in the base form, a `VB`, like *race*, therefore it is more likely that modal verbs will occur with main verb.\n",
    "  * We compute the maximum likelihood estimate of this transition probability by counting, out of the times we see the first tag in a labeled corpus, how often the first tag is followed by the second:\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  P(t_{i} | t_{i-1}) = \\frac{C(t_{i-1}, t_{i})}{C(t_{i-1})} \\\\\n",
    "  P(MD | VB) = \\frac{C(MD, VB)}{C(MD)}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "\n",
    "*   **Emission Probabilities** represents the probability, given a tag that it will be associated with a given word i.e. $P(w_i|t_i)$.\n",
    "  * For Example, probability of a given tag `MD` associated with the word *will* is:\n",
    "  $$\n",
    "  \\begin{equation}\n",
    "  P(w_i|t_i) = \\frac{C(t_i, w_i)}{C(t_i)} \\\\\n",
    "  P(will|MD) = \\frac{C(MD, \\text{will})}{C(MD)}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hLzHeEJBb8F"
   },
   "source": [
    "## Exercise 4: \n",
    "\n",
    "Consider that we have an HMM with hidden states Noun, Verb, Adj and the following transition probability where $p(Y_{i+1}|Y_i)$ is the probability of state $Y_{i+1}$ occuring after $Y_i$ and the table of probabilities is as follows:\n",
    "\n",
    "| $p(Y_{i+1}|Y_i)$ | $Y_{i+1}$=Start | $Y_{i+1}$=Noun | $Y_{i+1}$=Verb | $Y_{i+1}$=Adj |\n",
    "|:-----------------|:-----------------|:--------------:|:--------------:|:-------------:|\n",
    "| $Y_i$=Start      | 0.0      |  0.5           |  0.4           | 0.1           |\n",
    "| $Y_i$=Noun       | 0.0       |  0.3           |  0.5           | 0.2           |\n",
    "| $Y_i$=Verb       | 0.0       |  0.7           |  0.2           | 0.1           |\n",
    "| $Y_i$=Adj        | 0.0        |  0.8           |  0.1           | 0.1           |\n",
    "\n",
    "Furthermore, consider that the model has a vocabulary as follows, with the probability of $p(X_i|Y_i)$ as follows \n",
    "\n",
    "| $p(X_i|Y_i)$ | cats | dogs | drink | water | milk | fresh |\n",
    "|:-------------|:----:|:----:|:-----:|:-----:|:----:|:-----:|\n",
    "| $Y_i$=Noun   | 0.2  | 0.2  |  0.2  | 0.2   | 0.1  | 0.0   |\n",
    "| $Y_i$=Verb   | 0.1  | 0.1  | 0.4   | 0.2   | 0.1  | 0.1   |\n",
    "| $Y_i$=Adj    | 0.0  | 0.0  | 0.2   | 0.0   | 0.2  | 0.8   |\n",
    "\n",
    "\n",
    "Implement the above table and write a function that takes a sequence of words and a sequence of part-of-speech tags and returns the probability using the above model. Calculate the probability of the sentence \"*cats drink fresh milk*\" given the tags \"*noun verb adj verb*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "4RZV0xS7BiVB"
   },
   "outputs": [],
   "source": [
    "all_tags = [\"start\",\"noun\",\"verb\",\"adj\"]\n",
    "all_words = [\"cats\",\"dogs\",\"drink\",\"water\",\"milk\",\"fresh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "GM5PV12GULWT"
   },
   "outputs": [],
   "source": [
    "transitions = {\n",
    "  'start': {'noun': 0.5, 'verb': 0.4, 'adj': 0.1, 'start': 0.0},\n",
    "  'noun': {'noun': 0.3, 'verb': 0.5, 'adj': 0.2, 'start': 0.0},\n",
    "  'verb': {'noun': 0.7, 'verb': 0.2, 'adj': 0.1, 'start': 0.0},\n",
    "  'adj': {'noun': 0.8, 'verb': 0.1, 'adj': 0.1, 'start': 0.0},\n",
    "}\n",
    "\n",
    "\n",
    "emissions = {\n",
    "    # your code goes here\n",
    "    'noun': {'cats': 0.2, 'dogs': 0.2, 'drink': 0.2, 'water': 0.2, 'milk': 0.1, 'fresh':0.0},\n",
    "    'verb': {'cats': 0.1, 'dogs': 0.1, 'drink': 0.4, 'water': 0.2, 'milk': 0.1, 'fresh':0.1},\n",
    "    'adj': {'cats': 0.0, 'dogs': 0.0, 'drink': 0.2, 'water': 0.0, 'milk': 0.2, 'fresh':0.8},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "_moLAxIRBp7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6000000000000006e-05\n"
     ]
    }
   ],
   "source": [
    "def hmm(words, tags):\n",
    "    prob = 1.0\n",
    "    \n",
    "#     # your code goes here\n",
    "#     for i in range(len(words)-1, -1, -1):\n",
    "#         if i-1 == -1:\n",
    "#             prob = prob * transitions['start'][tags[i]] * emissions[tags[i]][words[i]]\n",
    "#         else:\n",
    "#             prob = prob * transitions[tags[i-1]][tags[i]] * emissions[tags[i]][words[i]]\n",
    "            \n",
    "    prev_tag = 'start'\n",
    "    for tag, word in zip(tags, words):\n",
    "        prob = prob * transitions[prev_tag][tag] * emissions[tag][word]\n",
    "        prev_tag = tag\n",
    "\n",
    "    return prob\n",
    "\n",
    "print(hmm([\"cats\",\"drink\",\"fresh\",\"milk\"], [\"noun\",\"verb\",\"adj\",\"verb\"]))\n",
    "# '''\n",
    "# p(v|a) * p(milk|v) = 0.1 * 0.1 = 0.01\n",
    "# p(a|v) * p(fresh|a) = 0.1 * 0.8 = 0.08\n",
    "# p(v|n) * p(drink|v) = 0.5 * 0.4 = 0.2\n",
    "# p(n|s) * p(cats|n) = 0.5 * 0.2 = 0.1\n",
    "# p(1.0)\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIVlRBrNEwbp"
   },
   "source": [
    "## Exercise 5 \n",
    "Write a function that learns the emission and transition probabilities for the Hidden Markov Model using the tagged corpus given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "g9A6RFCpEu-y"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    [\"cats\",\"drink\",\"milk\"],\n",
    "    [\"dogs\",\"drink\",\"water\"],\n",
    "    [\"fresh\",\"milk\"],\n",
    "    [\"dogs\",\"drink\",\"fresh\",\"milk\"],\n",
    "    [\"cats\",\"milk\"]\n",
    "]\n",
    "\n",
    "tagged = [\n",
    "    [\"noun\",\"verb\",\"noun\"],\n",
    "    [\"noun\",\"verb\",\"noun\"],\n",
    "    [\"adj\",\"noun\"],\n",
    "    [\"noun\",\"verb\",\"adj\",\"noun\"],\n",
    "    [\"noun\",\"noun\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "DxxjU0_XFBSc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': {'cats': 0.0, 'dogs': 0.0, 'drink': 0.0, 'water': 0.0, 'milk': 0.0, 'fresh': 0.0}, 'noun': {'cats': 0.2222222222222222, 'dogs': 0.2222222222222222, 'drink': 0.0, 'water': 0.1111111111111111, 'milk': 0.4444444444444444, 'fresh': 0.0}, 'verb': {'cats': 0.0, 'dogs': 0.0, 'drink': 1.0, 'water': 0.0, 'milk': 0.0, 'fresh': 0.0}, 'adj': {'cats': 0.0, 'dogs': 0.0, 'drink': 0.0, 'water': 0.0, 'milk': 0.0, 'fresh': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "def hmm_learn(sentences, tagged):\n",
    "    transitions = {t:{t2:0.0 for t2 in all_tags} for t in all_tags}\n",
    "    emissions   = {t:{w:0.0 for w in all_words} for t in all_tags}\n",
    "    # your code goes here\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        tag = tagged[i]\n",
    "        for j in range(len(sentence)-1, -1, -1):\n",
    "            if j-1 == -1:\n",
    "                transitions['start'][tag[j]] += 1\n",
    "            else:\n",
    "                transitions[tag[j-1]][tag[j]] += 1\n",
    "            emissions[tag[j]][sentence[j]] += 1\n",
    "            \n",
    "    transitions_counts = {t: sum(t2.values()) for t, t2 in transitions.items()}\n",
    "    emissions_counts = {t: sum(w.values()) for t, w in emissions.items()}\n",
    "#     print(transitions_counts, emissions_counts)   \n",
    "    \n",
    "    for t, t2 in transitions.items():\n",
    "        for k, v in t2.items():\n",
    "            transitions[t][k] = v/transitions_counts[t] \n",
    "    for t, w in emissions.items():    \n",
    "        for k, v in w.items():\n",
    "            if emissions_counts[t] != 0:\n",
    "                emissions[t][k] = v/emissions_counts[t] \n",
    "    \n",
    "    return transitions, emissions\n",
    "\n",
    "print(hmm_learn(sentences, tagged)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hint\n",
    "* Iterate through sentence and tag pair\n",
    "* Iterated through word and tag pair\n",
    "* Update the transitions and emission counts\n",
    "* Calculate the transitions_counts total and emissions_counts total by adding counts\n",
    "* normalize the tag counts\n",
    "* normalize the word counts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
